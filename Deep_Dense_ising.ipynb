{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89374e46",
   "metadata": {},
   "source": [
    "Intro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e717d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some libraries \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Input\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping \n",
    "#from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import requests\n",
    "import types\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# URL of the RAW .py file\n",
    "git_path = 'https://raw.githubusercontent.com/Nemenick/FCA_DeepNeuralNework-with-TensorFlow/main/'\n",
    "module_name = 'Ising2d'\n",
    "# Download the code\n",
    "response = requests.get(git_path + module_name + \".py\")\n",
    "code = response.text\n",
    "# Create a module object\n",
    "Ising2d = types.ModuleType(module_name)\n",
    "exec(code, Ising2d.__dict__)\n",
    "\n",
    "Termalizza = Ising2d.Termalizza  # funzione che mi termalizza 1 sola configurazione in 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d7886b",
   "metadata": {},
   "source": [
    "Neural network made up of only FullyConnected layers (or Dense layers)<br>\n",
    "The TensorFlow implementation is very fast during training and it is very easy to generalize<br>\n",
    "<ul>\n",
    "<li>a name of an example file accepted is 35conf4.dat<br>\n",
    "<li>Here 35 corresponds to the number of spin per dimension (35x35)</li>\n",
    "<li>and 4 corresponds to ntrain (or ntest or nval...) and it is the number of Temperature used.</li>\n",
    "<li>For each temperature I sample 20 configuration, so in 35conf4.dat i have 4x20=80 spin conf. (1 conf. is 1 raw)</li>\n",
    "<li>TODO read_file = True only if alredy generated my config.: \"(n)conf(ntrain).dat\" and \"(n)conf(ntest).dat\" alredy present</li>\n",
    "<li>TODO if readfile = false at first I generate my configurations (it takes a while...)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da3292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some initial parameters\n",
    "n=35                # number of spins in one direction\n",
    "ntrain=14           # number of training configurations\n",
    "nval=12             # number of validation configurations\n",
    "ntest=10            # number of test configurations\n",
    "read_file=True      # if True read the configurations from file, if False generate them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7ac79b",
   "metadata": {},
   "source": [
    "# Generate (or Load) my Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38602df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 1225)\n"
     ]
    }
   ],
   "source": [
    "data, data_val, data_test = [], [], []\n",
    "y, y_val, y_test = [], [], []\n",
    "if not read_file:\n",
    "    # In this section I generate my data rather than loading them\n",
    "    t = [0.1 + 3 / ntrain * i for i in range(ntrain // 2)] + [4 + 40 / ntrain * i for i in range(ntrain // 2)]\n",
    "    tc = 2 / np.log(1 + np.sqrt(2))\n",
    "    for temp in t:\n",
    "        spin = Termalizza(temp, L=n)\n",
    "        for _ in range(10):\n",
    "            if temp < tc:\n",
    "                y.append(0)\n",
    "            else:\n",
    "                y.append(1)\n",
    "            data.append([])\n",
    "            Termalizza(temp, L=n, spin=spin, equilibrato=True)\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    data[-1].append(spin[i + 1][j + 1])\n",
    "    print(\"Ho generato tutte le \\\"training\\\" configurazioni\")\n",
    "    data = np.array(data)\n",
    "\n",
    "    # Now i generate validation data\n",
    "    t = [0.1 + 3 / nval * i for i in range(nval // 2)] + [4 + 40 / nval * i for i in range(nval // 2)]\n",
    "    tc = 2 / np.log(1 + np.sqrt(2))\n",
    "    for temp in t:\n",
    "        spin = Termalizza(temp, L=n)\n",
    "        for _ in range(10):\n",
    "            if temp < tc:\n",
    "                y_val.append(0)\n",
    "            else:\n",
    "                y_val.append(1)\n",
    "            data_val.append([])\n",
    "            Termalizza(temp, L=n, spin=spin, equilibrato=True)\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    data_val[-1].append(spin[i + 1][j + 1])\n",
    "    print(\"Ho generato tutte le \\\"training\\\" configurazioni\")\n",
    "    data_val = np.array(data_val)\n",
    "\n",
    "    # Now i generate my test data\n",
    "    t = [0.1 + 3 / nval * i for i in range(nval // 2)] + [4 + 40 / nval * i for i in range(nval // 2)]\n",
    "    tc = 2 / np.log(1 + np.sqrt(2))\n",
    "    for temp in t:\n",
    "        spin = Termalizza(temp, L=n)\n",
    "        for _ in range(10):\n",
    "            if temp < tc:\n",
    "                y_test.append(0)\n",
    "            else:\n",
    "                y_test.append(1)\n",
    "            data_test.append([])\n",
    "            Termalizza(temp, L=n, spin=spin, equilibrato=True)\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    data_test[-1].append(spin[i + 1][j + 1])\n",
    "    print(\"Ho generato tutte le \\\"training\\\" configurazioni\")\n",
    "    data_test = np.array(data_test)\n",
    "\n",
    "else:\n",
    "    # if read_file I load my data than generating them! (files have to exist before I lunch this section)\n",
    "    # file = open(git_path + str(n) + \"conf\" + str(ntrain) + \".dat\", \"r\")\n",
    "    # file_y = open(git_path + str(n) + \"conf\" + str(ntrain) + \"y.dat\", \"r\")\n",
    "    data = np.loadtxt(urlopen(git_path + str(n) + \"conf\" + str(ntrain) + \".dat\"))\n",
    "    y = np.loadtxt(urlopen(git_path + str(n) + \"conf\" + str(ntrain) + \"y.dat\"))\n",
    "\n",
    "    # file = open(git_path + str(n) + \"conf\" + str(nval) + \".dat\", \"r\")\n",
    "    # file_y = open(str(n) + \"conf\" + str(nval) + \"y.dat\", \"r\")\n",
    "    data_val = np.loadtxt(urlopen(git_path + str(n) + \"conf\" + str(nval) + \".dat\"))\n",
    "    y_val = np.loadtxt(urlopen(git_path + str(n) + \"conf\" + str(nval) + \"y.dat\"))\n",
    "\n",
    "    # file = open(git_path + str(n) + \"conf\" + str(ntest) + \".dat\", \"r\")\n",
    "    # file_y = open(git_path + str(n) + \"conf\" + str(ntest) + \"y.dat\", \"r\")\n",
    "    data_test = np.loadtxt(urlopen(git_path + str(n) + \"conf\" + str(ntest) + \".dat\"))\n",
    "    y_test = np.loadtxt(urlopen(git_path + str(n) + \"conf\" + str(ntest) + \"y.dat\"))\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ee58c0",
   "metadata": {},
   "source": [
    "# Build and train my network\n",
    "<ul>\n",
    "<li> Change the hidden layer size and study the effect [(2), (5), (10), (25)]</li>\n",
    "<li> Add more layers. For example add the line \"Dense(5, activation=\"relu\"),\" after the first Dense layer</li>\n",
    "<li> Add Early Stopping</li>\n",
    "<li> Change activation function of hidden layers: sigmoid -> relu</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3b6721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                12260     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,271\n",
      "Trainable params: 12,271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rete1 = tensorflow.keras.models.Sequential([\n",
    "    Input(shape=(data.shape[1],)),\n",
    "    Dense(10,  activation=\"sigmoid\"),\n",
    "    Dense(1, activation=\"sigmoid\")])\n",
    "\n",
    "momento=0.8         # Parameter of the SGD optimizer\n",
    "rete1.compile(\n",
    "    optimizer=optimizers.SGD(momentum=momento),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=['accuracy'])\n",
    "rete1.summary()\n",
    "\n",
    "# Esercizio: Calcolare il numero di parametri del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4623176",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(rete1, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07886d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 1s 31ms/step - loss: 0.7072 - accuracy: 0.4679 - val_loss: 0.6936 - val_accuracy: 0.6458\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6866 - accuracy: 0.6500 - val_loss: 0.6933 - val_accuracy: 0.4417\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6647 - accuracy: 0.5500 - val_loss: 0.6922 - val_accuracy: 0.4625\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6499 - accuracy: 0.5964 - val_loss: 0.6894 - val_accuracy: 0.4833\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6336 - accuracy: 0.7393 - val_loss: 0.6898 - val_accuracy: 0.4750\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6165 - accuracy: 0.6714 - val_loss: 0.6917 - val_accuracy: 0.4625\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6011 - accuracy: 0.7357 - val_loss: 0.6894 - val_accuracy: 0.4542\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5857 - accuracy: 0.7143 - val_loss: 0.6909 - val_accuracy: 0.4375\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5719 - accuracy: 0.7357 - val_loss: 0.6911 - val_accuracy: 0.4333\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5575 - accuracy: 0.9107 - val_loss: 0.6927 - val_accuracy: 0.4250\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.8000 - val_loss: 0.6920 - val_accuracy: 0.6500\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5281 - accuracy: 0.8714 - val_loss: 0.6950 - val_accuracy: 0.6417\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.9643 - val_loss: 0.6963 - val_accuracy: 0.6417\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4976 - accuracy: 0.9679 - val_loss: 0.6969 - val_accuracy: 0.6417\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4869 - accuracy: 0.9679 - val_loss: 0.7026 - val_accuracy: 0.6375\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4715 - accuracy: 0.8429 - val_loss: 0.7024 - val_accuracy: 0.6375\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4602 - accuracy: 0.9714 - val_loss: 0.7071 - val_accuracy: 0.6250\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.9714 - val_loss: 0.7096 - val_accuracy: 0.6250\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.9714 - val_loss: 0.7108 - val_accuracy: 0.6375\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.9786 - val_loss: 0.7160 - val_accuracy: 0.6292\n",
      "\n",
      " dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# Start my training - \n",
    "batches, epoche, pazienza = 32, 20, 5\n",
    "storia = rete1.fit(data, y,\n",
    "                    batch_size=batches,\n",
    "                    epochs=epoche,\n",
    "                    validation_data=(data_val, y_val),\n",
    "                    ) #callbacks=EarlyStopping(patience=pazienza,  restore_best_weights=True)\n",
    "\n",
    "print(\"\\n\",storia.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cddce7",
   "metadata": {},
   "source": [
    "# Plots and test my network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "648a6825",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\"\"\"################################################### Plots ####################################################\"\"\"\n",
    "\n",
    "loss_train = storia.history[\"loss\"]\n",
    "loss_val = storia.history[\"val_loss\"]\n",
    "acc_train = storia.history[\"accuracy\"]\n",
    "acc_val = storia.history[\"val_accuracy\"]\n",
    "\n",
    "plt.plot(range(len(acc_train)), acc_train, label=\"acc_train\")\n",
    "plt.plot(range(len(acc_val)), acc_val, label=\"acc_val\")\n",
    "plt.legend()\n",
    "plt.savefig(\"Accuracy_Ising2d\")\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(range(len(loss_train)), loss_train, label=\"loss_train\")\n",
    "plt.plot(range(len(loss_val)), loss_val, label=\"loss_val\")\n",
    "plt.legend()\n",
    "plt.savefig(\"Loss_Ising2d\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a011c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"################################################### Test ####################################################\"\"\"\n",
    "\n",
    "yp_test = rete1.predict(data_test)                       # make my predictions\n",
    "yp_ok_test = []\n",
    "for i in yp_test:\n",
    "    yp_ok_test.append(i[0])\n",
    "yp_ok_test = np.array(yp_ok_test)\n",
    "\n",
    "total_predictions = len(y_test)\n",
    "correct_predictions = 0\n",
    "erroneous_predictions = 0                               # calculating the total, erroneous and correct predictions\n",
    "for i in range(total_predictions):\n",
    "    if abs(y_test[i] - yp_ok_test[i]) < 0.5:\n",
    "        correct_predictions = correct_predictions + 1\n",
    "    else:\n",
    "        erroneous_predictions = erroneous_predictions + 1\n",
    "\n",
    "print(\"test predictions:\\ntotal/correct/erroneous:\\n\", total_predictions, \"/\", correct_predictions, \"/\", erroneous_predictions, \"/\")\n",
    "print(\"test Accuracy= \", correct_predictions / total_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418f8d19",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4874e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1. -1. -1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " ...\n",
      " [-1. -1. -1. ... -1.  1. -1.]\n",
      " [-1. -1.  1. ... -1. -1.  1.]\n",
      " [ 1.  1. -1. ... -1. -1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "\n",
    "git_path = 'https://raw.githubusercontent.com/Nemenick/AIPHY24_GNN_Giagu/main/35conf10.dat'\n",
    "\n",
    "response = urlopen(git_path)\n",
    "data = np.loadtxt(response)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bee2fa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_path = 'https://raw.githubusercontent.com/Nemenick/FCA_DeepNeuralNework-with-TensorFlow/main/'\n",
    "# if read_file I load my data than generating them! (files have to exist before I lunch this section)\n",
    "# file = open(git_path + str(n) + \"conf\" + str(ntrain) + \".dat\", \"r\")\n",
    "# file_y = open(git_path + str(n) + \"conf\" + str(ntrain) + \"y.dat\", \"r\")\n",
    "data = np.loadtxt(urlopen(git_path + str(n) + \"conf\" + str(ntrain) + \".dat\"))\n",
    "y = np.loadtxt(urlopen(git_path + str(n) + \"conf\" + str(ntrain) + \"y.dat\"))\n",
    "\n",
    "# file = open(git_path + str(n) + \"conf\" + str(nval) + \".dat\", \"r\")\n",
    "# file_y = open(str(n) + \"conf\" + str(nval) + \"y.dat\", \"r\")\n",
    "data_val = np.loadtxt(urlopen(git_path + str(n) + \"conf\" + str(nval) + \".dat\"))\n",
    "y_val = np.loadtxt(urlopen(git_path + str(n) + \"conf\" + str(nval) + \"y.dat\"))\n",
    "\n",
    "# file = open(git_path + str(n) + \"conf\" + str(ntest) + \".dat\", \"r\")\n",
    "# file_y = open(git_path + str(n) + \"conf\" + str(ntest) + \"y.dat\", \"r\")\n",
    "data_test = np.loadtxt(urlopen(git_path + str(n) + \"conf\" + str(ntest) + \".dat\"))\n",
    "y_test = np.loadtxt(urlopen(git_path + str(n) + \"conf\" + str(ntest) + \"y.dat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d282542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://raw.githubusercontent.com/Nemenick/AIPHY24_GNN_Giagu/main/35conf10.dat'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "117ac0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<http.client.HTTPResponse at 0x228e0b24490>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envpulito",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
